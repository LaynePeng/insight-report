#!/usr/bin/env python3
"""
YouTubeæŠ€æœ¯æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå™¨ (é‡æ„ç‰ˆ)
ä»YouTubeè§†é¢‘æå–å­—å¹•å¹¶ä½¿ç”¨LLMç”ŸæˆæŠ€æœ¯åˆ†ææŠ¥å‘Šã€‚
æ”¯æŒé•¿å­—å¹•è‡ªåŠ¨åˆ†å—å¤„ç†ã€‚
"""

import re
import yaml
import time
import requests
import yt_dlp
import os
import sys
from pathlib import Path
from typing import Optional, Dict, Any, List

class YouTubeAnalyzer:
    """
    ä¸»åˆ†æå™¨ç±»ï¼Œæ•´åˆäº†é…ç½®åŠ è½½ã€å­—å¹•æå–ã€LLMåˆ†æå’Œæ–‡ä»¶ä¿å­˜åŠŸèƒ½ã€‚
    """

    DEFAULT_CONFIG = """
llm:
  base_url: "https://api.openai.com/v1"
  api_key: ""
  model: "gpt-3.5-turbo"
  max_chars: 15000  # å­—å¹•åˆ†å—å¤„ç†çš„å•å—æœ€å¤§å­—ç¬¦æ•°

prompts:
  system_prompt: "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æŠ€æœ¯åˆ†æå¸ˆï¼Œæ“…é•¿ä»æŠ€æœ¯è§†é¢‘å†…å®¹ä¸­æå–å…³é”®æ´å¯Ÿã€‚"
  analysis_prompt: |
    è¯·åˆ†æä»¥ä¸‹è§†é¢‘å­—å¹•å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½æŠ€æœ¯æ´å¯ŸæŠ¥å‘Šã€‚
    æŠ¥å‘Šåº”åŒ…å«æ ¸å¿ƒæŠ€æœ¯æ¦‚å¿µã€å…³é”®è¦ç‚¹æ€»ç»“ã€å®è·µåº”ç”¨å»ºè®®ç­‰ã€‚
    è¯·ä½¿ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„ä¸­æ–‡è¾“å‡ºã€‚

    å­—å¹•å†…å®¹ï¼š
    {transcript}
  
  summary_prompt: |
    è¯·æ€»ç»“ä»¥ä¸‹å­—å¹•çš„æ ¸å¿ƒå†…å®¹ï¼Œç”¨äºåç»­çš„æ•´åˆåˆ†æã€‚
    æ€»ç»“åº”ç®€æ˜æ‰¼è¦ï¼Œçªå‡ºå…³é”®ä¿¡æ¯ã€‚

    å­—å¹•å†…å®¹ï¼š
    {transcript}

subtitle:
  preferred_languages: ['zh-Hans', 'zh-CN', 'zh', 'en']

output:
  reports_dir: "reports"
  save_subtitles: true
  format: "md"
"""

    def __init__(self, config_path: str = "config.yaml", api_key: Optional[str] = None):
        self.config_path = config_path
        self.config = self._load_or_create_config()
        
        # API Key ä¼˜å…ˆçº§: å‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é…ç½®æ–‡ä»¶
        self.api_key = api_key or os.getenv("LLM_API_KEY") or self.config.get('llm', {}).get('api_key')
        
        if not self.api_key or "YOUR_API_KEY" in self.api_key:
            self.api_key = input("è¯·è¾“å…¥ä½ çš„LLM API Key: ").strip()
            if not self.api_key:
                print("é”™è¯¯: æœªæä¾›æœ‰æ•ˆçš„API Keyã€‚")
                sys.exit(1)

        self.reports_dir = Path(self.config.get('output', {}).get('reports_dir', 'reports'))
        self.reports_dir.mkdir(exist_ok=True)

    def _load_or_create_config(self) -> Dict[str, Any]:
        """åŠ è½½æˆ–åˆ›å»ºé…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.config_path):
            print(f"é…ç½®æ–‡ä»¶ {self.config_path} ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤æ¨¡æ¿...")
            try:
                with open(self.config_path, 'w', encoding='utf-8') as f:
                    f.write(self.DEFAULT_CONFIG)
                print(f"é»˜è®¤é…ç½®å·²åˆ›å»ºï¼Œä½ å¯ä»¥åœ¨ {self.config_path} ä¸­ä¿®æ”¹ã€‚")
            except IOError as e:
                print(f"æ— æ³•åˆ›å»ºé…ç½®æ–‡ä»¶: {e}")
                sys.exit(1)
        
        try:
            with open(self.config_path, 'r', encoding='utf-8') as file:
                return yaml.safe_load(file) or {}
        except yaml.YAMLError as e:
            print(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            sys.exit(1)

    def _extract_subtitle(self, video_url: str) -> str:
        """ä½¿ç”¨ yt-dlp æå–å­—å¹•"""
        temp_prefix = f"temp_sub_{int(time.time())}"
        subtitle_config = self.config.get('subtitle', {})
        preferred_languages = subtitle_config.get('preferred_languages', ['en'])
        browser_for_cookies = subtitle_config.get('browser_for_cookies')
        cookies_file = subtitle_config.get('cookies_file')
        
        ydl_opts: Dict[str, Any] = {
            'skip_download': True,
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': preferred_languages,
            'subtitlesformat': 'vtt',
            'outtmpl': temp_prefix,
            'quiet': True,
            'no_warnings': True,
            'no_check_certificate': True, # è§£å†³ SSL è¯ä¹¦é—®é¢˜
        }

        # --- Cookie é…ç½® ---
        # ä¼˜å…ˆä½¿ç”¨ browser_for_cookies
        if browser_for_cookies:
            print(f"å°è¯•ä»æµè§ˆå™¨ '{browser_for_cookies}' è‡ªåŠ¨åŠ è½½ cookies...")
            ydl_opts['cookiesfrombrowser'] = (browser_for_cookies, )
        elif cookies_file and os.path.exists(cookies_file):
            print(f"ä½¿ç”¨ cookies æ–‡ä»¶: {cookies_file}")
            ydl_opts['cookies'] = cookies_file

        downloaded_file = None
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                print("æ­£åœ¨è·å–è§†é¢‘ä¿¡æ¯å¹¶ä¸‹è½½å­—å¹•...")
                ydl.extract_info(video_url, download=True)
                
                for file in os.listdir('.'):
                    if file.startswith(temp_prefix) and file.endswith('.vtt'):
                        downloaded_file = file
                        break
                
                if not downloaded_file:
                    raise ValueError("æœªæ‰¾åˆ°å¯ä¸‹è½½çš„å­—å¹•æ–‡ä»¶ã€‚")

                with open(downloaded_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                return self._clean_vtt_text(content)
        except Exception as e:
            raise RuntimeError(f"å­—å¹•æå–å¤±è´¥: {e}")
        finally:
            if downloaded_file and os.path.exists(downloaded_file):
                os.remove(downloaded_file)

    def _clean_vtt_text(self, vtt_text: str) -> str:
        """æ¸…ç† VTT å­—å¹•æ ¼å¼"""
        lines = vtt_text.splitlines()
        cleaned_lines = []
        seen_lines = set()
        for line in lines:
            line = line.strip()
            if '-->' in line or line.isdigit() or not line or \
               line.startswith('WEBVTT') or line.startswith('Kind:') or \
               line.startswith('Language:'):
                continue
            line = re.sub(r'<[^>]+>', '', line)
            if line not in seen_lines:
                cleaned_lines.append(line)
                seen_lines.add(line)
        return "\n".join(cleaned_lines)

    def _call_llm(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨LLM API"""
        llm_config = self.config.get('llm', {})
        base_url = llm_config.get('base_url', '').rstrip('/')
        model = llm_config.get('model')

        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.5,
        }

        try:
            url = f"{base_url}/chat/completions"
            response = requests.post(url, headers=headers, json=data, timeout=180)
            response.raise_for_status()
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
        except requests.RequestException as e:
            raise RuntimeError(f"API è¯·æ±‚å¤±è´¥: {e}, å“åº”: {e.response.text if e.response else 'N/A'}")

    def _generate_report_for_chunk(self, transcript_chunk: str, is_summary: bool) -> str:
        """ä¸ºå•ä¸ªæ–‡æœ¬å—ç”ŸæˆæŠ¥å‘Šæˆ–æ‘˜è¦"""
        prompts_config = self.config.get('prompts', {})
        system_prompt = prompts_config.get('system_prompt', '')
        
        if is_summary:
            prompt_template = prompts_config.get('summary_prompt', '{transcript}')
        else:
            prompt_template = prompts_config.get('analysis_prompt', '{transcript}')
            
        user_prompt = prompt_template.format(transcript=transcript_chunk)
        return self._call_llm(system_prompt, user_prompt)

    def _process_long_transcript(self, transcript: str) -> str:
        """å¤„ç†é•¿å­—å¹•ï¼Œåˆ†å—æ€»ç»“å†æ•´åˆåˆ†æ"""
        max_chars = self.config.get('llm', {}).get('max_chars', 15000)
        
        if len(transcript) <= max_chars:
            print("å­—å¹•é•¿åº¦é€‚ä¸­ï¼Œç›´æ¥ç”ŸæˆæŠ¥å‘Š...")
            return self._generate_report_for_chunk(transcript, is_summary=False)

        print(f"å­—å¹•è¿‡é•¿({len(transcript)} > {max_chars})ï¼Œå¯åŠ¨åˆ†å—æ€»ç»“æ¨¡å¼...")
        chunks = [transcript[i:i+max_chars] for i in range(0, len(transcript), max_chars)]
        summaries = []

        for i, chunk in enumerate(chunks):
            print(f"æ­£åœ¨å¤„ç†åˆ†å— {i+1}/{len(chunks)}...")
            summary = self._generate_report_for_chunk(chunk, is_summary=True)
            summaries.append(summary)
            print(f"åˆ†å— {i+1} æ€»ç»“å®Œæˆã€‚")

        print("æ‰€æœ‰åˆ†å—æ€»ç»“å®Œæ¯•ï¼Œæ­£åœ¨è¿›è¡Œæœ€ç»ˆæ•´åˆåˆ†æ...")
        combined_summary = "\n\n".join(summaries)
        
        # ä¿å­˜æ•´åˆåçš„æ‘˜è¦ï¼Œä¾¿äºè°ƒè¯•
        self._save_text("combined_summary", combined_summary, suffix="_summary.txt")

        final_report = self._generate_report_for_chunk(combined_summary, is_summary=False)
        return final_report

    def run(self, video_url: str):
        """æ‰§è¡Œä¸»åˆ†ææµç¨‹"""
        print(f"=== å¼€å§‹åˆ†æè§†é¢‘: {video_url} ===")
        try:
            transcript = self._extract_subtitle(video_url)
            print(f"å­—å¹•æå–æˆåŠŸï¼Œé•¿åº¦: {len(transcript)} å­—ç¬¦ã€‚")
            
            if self.config.get('output', {}).get('save_subtitles'):
                self._save_text(video_url, transcript, suffix="_raw_transcript.txt")

            report = self._process_long_transcript(transcript)
            
            report_format = self.config.get('output', {}).get('format', 'md')
            report_path = self._save_text(video_url, report, suffix=f"_report.{report_format}")
            
            print("\n" + "="*30)
            print("âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
            print(f"ğŸ“„ æ–‡ä»¶è·¯å¾„: {report_path}")
            print("="*30 + "\n")
            print("--- æŠ¥å‘Šé¢„è§ˆ ---")
            print(report[:400] + "..." if len(report) > 400 else report)

        except (RuntimeError, ValueError) as e:
            print(f"\nâŒ ä»»åŠ¡å¤±è´¥: {e}")

    def _save_text(self, identifier: str, content: str, suffix: str) -> Path:
        """ä¿å­˜æ–‡æœ¬å†…å®¹åˆ°æ–‡ä»¶"""
        if "http" in identifier:
            match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', identifier)
            video_id = match.group(1) if match else "unknown_video"
        else:
            video_id = identifier
            
        filename = f"{video_id}{suffix}"
        path = self.reports_dir / filename
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        return path

def main():
    import argparse
    parser = argparse.ArgumentParser(
        description='YouTube AI æŠ¥å‘Šç”Ÿæˆå™¨ (é‡æ„ç‰ˆ)',
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument('url', help='YouTube è§†é¢‘é“¾æ¥')
    parser.add_argument('--config', default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument(
        '--api-key', 
        help='LLM API Keyã€‚\nä¼˜å…ˆçº§: æ­¤å‚æ•° > ç¯å¢ƒå˜é‡(LLM_API_KEY) > é…ç½®æ–‡ä»¶ > æ‰‹åŠ¨è¾“å…¥'
    )
    args = parser.parse_args()

    analyzer = YouTubeAnalyzer(config_path=args.config, api_key=args.api_key)
    analyzer.run(args.url)

if __name__ == "__main__":
    main()

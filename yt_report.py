#!/usr/bin/env python3
"""
YouTubeæŠ€æœ¯æ´å¯ŸæŠ¥å‘Šç”Ÿæˆå™¨
ä»YouTubeè§†é¢‘æå–å­—å¹•å¹¶ä½¿ç”¨LLMç”ŸæˆæŠ€æœ¯åˆ†ææŠ¥å‘Šã€‚
æ”¯æŒé•¿å­—å¹•è‡ªåŠ¨åˆ†å—å¤„ç†ã€‚
"""

import re
import yaml
import time
import requests
import yt_dlp
import os
import sys
from pathlib import Path
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class ConfigLoader:
    """é…ç½®åŠ è½½å™¨ï¼Œè´Ÿè´£åŠ è½½å’ŒéªŒè¯é…ç½®æ–‡ä»¶"""
    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = config_path

    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.config_path):
            print(f"âŒ é”™è¯¯: é…ç½®æ–‡ä»¶ {self.config_path} ä¸å­˜åœ¨áº£ng")
            print("è¯·ç¡®ä¿ç›®å½•ä¸‹å­˜åœ¨æ­£ç¡®çš„ config.yaml æ–‡ä»¶áº£ng")
            sys.exit(1)
        
        try:
            with open(self.config_path, 'r', encoding='utf-8') as file:
                config = yaml.safe_load(file) or {}
                return config
        except yaml.YAMLError as e:
            print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            sys.exit(1)

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ï¼Œè´Ÿè´£æ–‡ä»¶è¯»å†™å’Œä¸´æ—¶ç›®å½•ç®¡ç†"""
    def __init__(self, reports_dir: str):
        self.reports_dir = Path(reports_dir)
        self.reports_dir.mkdir(parents=True, exist_ok=True)

    def get_temp_dir(self, video_id: str) -> Path:
        """è·å–ç‰¹å®šè§†é¢‘çš„ä¸´æ—¶ç›®å½•"""
        temp_dir = self.reports_dir / "temp" / video_id
        temp_dir.mkdir(parents=True, exist_ok=True)
        return temp_dir

    def save_text(self, path: Path, content: str):
        """ä¿å­˜æ–‡æœ¬åˆ°æ–‡ä»¶"""
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)

    def load_text(self, path: Path) -> str:
        """ä»æ–‡ä»¶åŠ è½½æ–‡æœ¬"""
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()

    def exists(self, path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        return path.exists()

class SubtitleService:
    """å­—å¹•æœåŠ¡ï¼Œè´Ÿè´£æå–å’Œæ¸…æ´—å­—å¹•"""
    def __init__(self, config: Dict[str, Any]):
        self.config = config.get('subtitle', {})

    def extract_subtitle(self, video_url: str, temp_dir: Path) -> str:
        """ä½¿ç”¨ yt-dlp æå–å­—å¹•"""
        temp_prefix = f"temp_sub_{int(time.time())}"
        preferred_languages = self.config.get('preferred_languages', ['en'])
        browser_for_cookies = self.config.get('browser_for_cookies')
        cookies_file = self.config.get('cookies_file')
        
        # æ„å»ºå®Œæ•´çš„è¾“å‡ºæ¨¡æ¿è·¯å¾„ï¼Œå°†å­—å¹•æ–‡ä»¶ä¿å­˜åˆ° temp_dir ä¸­
        output_template = str(temp_dir / temp_prefix)

        ydl_opts: Dict[str, Any] = {
            'skip_download': True,
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': preferred_languages,
            'subtitlesformat': 'vtt',
            'outtmpl': output_template, # ä½¿ç”¨å®Œæ•´çš„è·¯å¾„
            'quiet': True,
            'no_warnings': True,
            'no_check_certificate': True,
        }

        # --- Cookie é…ç½® ---
        if browser_for_cookies:
            print(f"å°è¯•ä»æµè§ˆå™¨ '{browser_for_cookies}' è‡ªåŠ¨åŠ è½½ cookies...")
            ydl_opts['cookiesfrombrowser'] = (browser_for_cookies, )
        elif cookies_file and os.path.exists(cookies_file):
            print(f"ä½¿ç”¨ cookies æ–‡ä»¶: {cookies_file}")
            ydl_opts['cookies'] = cookies_file

        downloaded_file = None
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl: # type: ignore
                print("æ­£åœ¨è·å–è§†é¢‘ä¿¡æ¯å¹¶ä¸‹è½½å­—å¹•...")
                ydl.extract_info(video_url, download=True)
                
                # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
                downloaded_file_path = None
                for file in os.listdir(temp_dir):
                    if file.startswith(temp_prefix) and file.endswith('.vtt'):
                        downloaded_file_path = temp_dir / file
                        break
                
                if not downloaded_file_path:
                    raise ValueError("æœªæ‰¾åˆ°å¯ä¸‹è½½çš„å­—å¹•æ–‡ä»¶áº£ng")

                with open(downloaded_file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                return self._clean_vtt_text(content)
        except Exception as e:
            raise RuntimeError(f"å­—å¹•æå–å¤±è´¥: {e}")
        finally:
            if downloaded_file_path and os.path.exists(downloaded_file_path): # type: ignore
                os.remove(downloaded_file_path)

    def _clean_vtt_text(self, vtt_text: str) -> str:
        """æ¸…æ´— VTT å­—å¹•æ ¼å¼"""
        lines = vtt_text.splitlines()
        cleaned_lines = []
        seen_lines = set()
        for line in lines:
            line = line.strip()
            if '-->' in line or line.isdigit() or not line or \
               line.startswith('WEBVTT') or line.startswith('Kind:') or \
               line.startswith('Language:'):
                continue
            line = re.sub(r'<[^>]+>', '', line)
            if line not in seen_lines:
                cleaned_lines.append(line)
                seen_lines.add(line)
        return "\n".join(cleaned_lines)

class LLMService:
    """LLM æœåŠ¡ï¼Œè´Ÿè´£ä¸å¤§æ¨¡å‹ API äº¤äº’"""
    def __init__(self, config: Dict[str, Any], api_key: str):
        self.config = config.get('llm', {})
        self.api_key = api_key
        self.provider = self.config.get('provider', 'openai')
        self.base_url = self.config.get('base_url', '').rstrip('/')
        self.model = self.config.get('model')
        
        if self.provider == 'gemini':
            try:
                import google.generativeai as genai
                self.genai = genai
                self.genai.configure(api_key=self.api_key) # type: ignore
                self.genai_model = self.genai.GenerativeModel(self.model) # type: ignore
            except ImportError:
                print("âŒ é”™è¯¯: æœªæ‰¾åˆ° google-generativeai åº“ã€‚è¯·è¿è¡Œ pip install google-generativeai")
                sys.exit(1)

    def call_llm(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨ LLM API"""
        if self.provider == 'gemini':
            return self._call_gemini(system_prompt, user_prompt)
        else:
            return self._call_openai(system_prompt, user_prompt)

    def _call_gemini(self, system_prompt: str, user_prompt: str) -> str:
        try:
            # Gemini SDK å»ºè®®å°† system prompt åŒ…å«åœ¨ modelé…ç½®ä¸­æˆ–ç›´æ¥æ‹¼æ¥
            # è¿™é‡Œé‡‡ç”¨æ‹¼æ¥æ–¹å¼ä»¥æ”¯æŒåŠ¨æ€ system prompt
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            response = self.genai_model.generate_content(full_prompt)
            return response.text
        except Exception as e:
            raise RuntimeError(f"Gemini API è°ƒç”¨å¤±è´¥: {e}")

    def _call_openai(self, system_prompt: str, user_prompt: str) -> str:
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.5,
        }

        try:
            url = f"{self.base_url}/chat/completions"
            response = requests.post(url, headers=headers, json=data, timeout=180)
            response.raise_for_status()
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
        except requests.RequestException as e:
            error_msg = f"API è¯·æ±‚å¤±è´¥: {e}"
            if e.response is not None:
                error_msg += f", å“åº”: {e.response.text}"
            raise RuntimeError(error_msg)

class YouTubeAnalyzer:
    """ä¸»åˆ†æå™¨ï¼Œåè°ƒå„ä¸ªæœåŠ¡ç”ŸæˆæŠ¥å‘Š"""
    def __init__(self, 
                 config: Dict[str, Any], 
                 subtitle_service: SubtitleService, 
                 llm_service: LLMService, 
                 cache_manager: CacheManager):
        self.config = config
        self.subtitle_service = subtitle_service
        self.llm_service = llm_service
        self.cache_manager = cache_manager
        self.prompts_config = config.get('prompts', {})

    def _get_video_id(self, video_url: str) -> str:
        """ä» URL æå–è§†é¢‘ ID"""
        match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', video_url)
        if not match:
            raise ValueError("æ— æ³•ä» URL ä¸­æå–æœ‰æ•ˆçš„ YouTube è§†é¢‘ ID")
        return match.group(1)

    def _generate_report_for_chunk(self, transcript_chunk: str, is_summary: bool) -> str:
        """ä¸ºå•ä¸ªæ–‡æœ¬å—ç”ŸæˆæŠ¥å‘Šæˆ–æ‘˜è¦"""
        system_prompt = self.prompts_config.get('system_prompt', '')
        
        if is_summary:
            prompt_template = self.prompts_config.get('summary_prompt', '{transcript}')
        else:
            prompt_template = self.prompts_config.get('analysis_prompt', '{transcript}')
            
        user_prompt = prompt_template.format(transcript=transcript_chunk)
        return self.llm_service.call_llm(system_prompt, user_prompt)

    def _process_long_transcript(self, transcript: str, temp_dir: Path) -> str:
        """å¤„ç†é•¿å­—å¹•ï¼šåˆ†å— -> æ€»ç»“ -> æ•´åˆåˆ†æ"""
        max_chars = self.config.get('llm', {}).get('max_chars', 15000)
        
        if len(transcript) <= max_chars:
            print("å­—å¹•é•¿åº¦é€‚ä¸­ï¼Œç›´æ¥ç”ŸæˆæŠ¥å‘Š...")
            return self._generate_report_for_chunk(transcript, is_summary=False)

        print(f"å­—å¹•è¿‡é•¿({len(transcript)} > {max_chars})ï¼Œå¯åŠ¨åˆ†å—æ€»ç»“æ¨¡å¼áº£ng")
        chunks = [transcript[i:i+max_chars] for i in range(0, len(transcript), max_chars)]
        summaries = []

        for i, chunk in enumerate(chunks):
            summary_path = temp_dir / f"chunk_{i+1}_summary.txt"
            
            if self.cache_manager.exists(summary_path):
                print(f"åˆ†å— {i+1}/{len(chunks)} çš„æ‘˜è¦å·²å­˜åœ¨ï¼Œä»ç¼“å­˜åŠ è½½...")
                summary = self.cache_manager.load_text(summary_path)
            else:
                print(f"æ­£åœ¨å¤„ç†åˆ†å— {i+1}/{len(chunks)}...")
                summary = self._generate_report_for_chunk(chunk, is_summary=True)
                self.cache_manager.save_text(summary_path, summary)
                print(f"åˆ†å— {i+1} æ€»ç»“å®Œæˆï¼Œå¹¶å·²ç¼“å­˜áº£ng")
            
            summaries.append(summary)

        print("æ‰€æœ‰åˆ†å—æ€»ç»“å®Œæ¯•ï¼Œæ­£åœ¨è¿›è¡Œæœ€ç»ˆæ•´åˆåˆ†æ...")
        combined_summary = "\n\n".join(summaries)
        
        # ä¿å­˜æ•´åˆåçš„æ‘˜è¦ä»¥ä¾¿è°ƒè¯•
        combined_summary_path = temp_dir / "combined_summary.txt"
        self.cache_manager.save_text(combined_summary_path, combined_summary)
        
        final_report = self._generate_report_for_chunk(combined_summary, is_summary=False)
        return final_report

    def run(self, video_url: str):
        """æ‰§è¡Œä¸»æµç¨‹"""
        try:
            video_id = self._get_video_id(video_url)
            temp_dir = self.cache_manager.get_temp_dir(video_id)
            
            print(f"=== å¼€å§‹åˆ†æè§†é¢‘: {video_url} (ID: {video_id}) ===")
            
            # 1. è·å–å­—å¹•
            transcript_path = temp_dir / "transcript.txt"
            if self.cache_manager.exists(transcript_path):
                print("ä»ç¼“å­˜åŠ è½½å­—å¹•...")
                transcript = self.cache_manager.load_text(transcript_path)
            else:
                transcript = self.subtitle_service.extract_subtitle(video_url, temp_dir)
                self.cache_manager.save_text(transcript_path, transcript)
            
            print(f"å­—å¹•å¤„ç†å®Œæˆï¼Œé•¿åº¦: {len(transcript)} å­—ç¬¦áº£ng")

            # 2. ç”ŸæˆæŠ¥å‘Š
            report = self._process_long_transcript(transcript, temp_dir)
            
            # 3. ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
            report_format = self.config.get('output', {}).get('format', 'md')
            report_filename = f"{video_id}_report.{report_format}"
            report_path = self.cache_manager.reports_dir / report_filename
            self.cache_manager.save_text(report_path, report)
            
            print("\n" + "="*30)
            print("âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸáº£ng")
            print(f"ğŸ“„ æ–‡ä»¶è·¯å¾„: {report_path}")
            print(f"â„¹ï¸  ä¸­é—´æ–‡ä»¶ä¿å­˜åœ¨: {temp_dir}")
            print("="*30 + "\n")
            print("--- æŠ¥å‘Šé¢„è§ˆ ---")
            print(report[:400] + "..." if len(report) > 400 else report)

        except (RuntimeError, ValueError) as e:
            print(f"\nâŒ ä»»åŠ¡å¤±è´¥: {e}")

def main():
    import argparse
    parser = argparse.ArgumentParser(
        description='YouTube AI æŠ¥å‘Šç”Ÿæˆå™¨',
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument('url', help='YouTube è§†é¢‘é“¾æ¥')
    parser.add_argument('--config', default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument(
        '--api-key', 
        help='LLM API Keyã€‚\nä¼˜å…ˆçº§: æ­¤å‚æ•° > ç¯å¢ƒå˜é‡(LLM_API_KEY) > é…ç½®æ–‡ä»¶ > æ‰‹åŠ¨è¾“å…¥'
    )
    args = parser.parse_args()

    # 1. åŠ è½½é…ç½®
    config_loader = ConfigLoader(args.config)
    config = config_loader.load_config()

    # 2. è·å– API Key
    api_key = args.api_key or os.getenv("LLM_API_KEY") or config.get('llm', {}).get('api_key')
    if not api_key or "YOUR_API_KEY" in api_key:
        api_key = input("è¯·è¾“å…¥ä½ çš„LLM API Key: ").strip()
        if not api_key:
            print("âŒ é”™è¯¯: æœªæä¾›æœ‰æ•ˆçš„API Keyáº£ng")
            sys.exit(1)

    # 3. åˆå§‹åŒ–æœåŠ¡
    cache_manager = CacheManager(config.get('output', {}).get('reports_dir', 'reports'))
    subtitle_service = SubtitleService(config)
    llm_service = LLMService(config, api_key)

    # 4. è¿è¡Œåˆ†æå™¨
    analyzer = YouTubeAnalyzer(config, subtitle_service, llm_service, cache_manager)
    analyzer.run(args.url)

if __name__ == "__main__":
    main()